{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This project was a failure\n",
    "\n",
    "The inspiration for this project was this video on the complexity of rapping and rhyme schemes throughout the history of rap: https://www.youtube.com/watch?v=QWveXdj6oZU\n",
    "\n",
    "The goal of this project was to find and analyze the occurance of multisyllable rhymes in the history of rap music using genetic sequence analysis for feature extraction. Multisyllabic rhyme schemes are cited as being more complex and more impressive than their simple counterparts, however from a programmatic perspective they are also far more difficult to find and address.\n",
    "\n",
    "My aim of finding these trends within the greater scheme of popular rap music was not successful, as I had difficulty pulling significant metrics from the data I had found. My progress and methods have been highlighted below.\n",
    "\n",
    "### Step 1: Data cleaning\n",
    "Starting with an example text, in this case \"lose yourself\" by eminem first step is to clean and split the data into managable chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pronouncing\n",
    "import string\n",
    "from collections import Counter\n",
    "import repeats as rpts\n",
    "from helper import *\n",
    "\n",
    "lyrics = '''\n",
    "His palms are sweaty, knees weak, arms are heavy\n",
    "There's vomit on his sweater already, mom's spaghetti\n",
    "He's nervous, but on the surface he looks calm and ready\n",
    "To drop bombs, but he keeps on forgettin'\n",
    "What he wrote down, the whole crowd goes so loud\n",
    "He opens his mouth, but the words won't come out\n",
    "He's chokin', how, everybody's jokin' now\n",
    "The clocks run out, times up, over, blaow!\n",
    "Snap back to reality, oh there goes gravity\n",
    "Oh, there goes Rabbit, he choked\n",
    "He's so mad, but he won't give up that easy? No\n",
    "He won't have it, he knows his whole back city's ropes\n",
    "It don't matter, he's dope, he knows that, but he's broke\n",
    "He's so stacked that he knows, when he goes back to his mobile home, that's when its\n",
    "Back to the lab again yo, this whole rhapsody\n",
    "He better go capture this moment and hope it don't pass him\n",
    "\n",
    "You better lose yourself in the music, the moment\n",
    "You own it, you better never let it go\n",
    "You only get one shot, do not miss your chance to blow\n",
    "This opportunity comes once in a lifetime you better\n",
    "\n",
    "You better lose yourself in the music, the moment\n",
    "You own it, you better never let it go\n",
    "You only get one shot, do not miss your chance to blow\n",
    "This opportunity comes once in a lifetime you better\n",
    "'''\n",
    "\n",
    "clean = clean_text(lyrics)  \n",
    "words = clean.split()\n",
    "word_bag = Counter(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Phonetic extraction\n",
    "With clean data the next goal was to get phonetic decompositions of all words in the song. With phonetic data I would be able to find and match different vowel phonems in order to find rhymes within the song. I used the \"pronouncing\" package available here: https://pypi.python.org/pypi/phonetics. Note that this package includes rhyme finding, however it is very simplistic, finding only perfect, single word rhymes. My goal was to extend this to more complex, multi-word, multi-syllable rhymes\n",
    "\n",
    "This package is built off of the CMU prononcing dictionary available here: http://www.speech.cs.cmu.edu/cgi-bin/cmudict\n",
    "\n",
    "This package is able to break down most common words into their phonetic decompositions, and further will provide multiple decompositions for different dialects or parts of speech. To deal with multiple pronunciations for a single word, I first found all potential pronunciations, found the most common vowel phonems, and chose the pronunciation that fit with the most common of the text. This method was chosen to maximize potential rhymes from a given lyric, a goal that many rappers have when writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his\n",
      "['IH0']\n",
      "palms\n",
      "['AA1']\n",
      "are\n",
      "['AA1']\n",
      "sweaty\n",
      "['EH1', 'IY0']\n",
      "knees\n",
      "['IY1']\n"
     ]
    }
   ],
   "source": [
    "phones = load_phones()\n",
    "\n",
    "# Generate pronuncation dictionary\n",
    "def pron_dict(unique):\n",
    "    prons = {}\n",
    "    for word in unique:\n",
    "        # Find pronuncation for each word\n",
    "        word_phones = map(lambda x: x.split(), pronouncing.phones_for_word(word))\n",
    "        \n",
    "        # Extract vowel phonems\n",
    "        word_vowels = []\n",
    "        for phone in word_phones:\n",
    "            word_vowels.append([x for x in phone if x in phones['vowel']])\n",
    "        \n",
    "        prons[word] = word_vowels\n",
    "    \n",
    "    # Count all vowel phonems\n",
    "    cts = Counter(flt(flt(list(prons.values()))))\n",
    "    \n",
    "    # Optimize pronunciation dictionary for maximum vowel phonem overlap\n",
    "    for word in unique:\n",
    "        prons[word] = best(cts,prons[word])\n",
    "\n",
    "    return prons\n",
    "\n",
    "# Given a choice of pronuncations and a count of the current text, chose \n",
    "# pronunciation that maximizes similarity\n",
    "def best(cts, prons):\n",
    "    if len(prons) > 1:\n",
    "        scores = []\n",
    "        for pron in prons:\n",
    "            # score pronunciation based off of frequency of phonem\n",
    "            score = 0\n",
    "            for phone in pron:\n",
    "                score += cts[phone]\n",
    "            scores.append(score)\n",
    "        \n",
    "        # Choose best phonetic representation\n",
    "        return prons[scores.index(max(scores))]\n",
    "    elif len(prons) == 1:\n",
    "        return prons[0]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "prons = pron_dict(word_bag.keys())\n",
    "for key in list(prons.keys())[0:5]:\n",
    "    print(key)\n",
    "    print(prons[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Prepare for sequence analysis\n",
    "The important part of multisyllable rhyming is that it is positional dependent, and thus 'bag of words' operations cannot find rhymes within text. Further, multisyllable rhymes do not care where word boundaries lay, but rather focus on the sequence of vowel phonems within them. Thus, in order to extract rhymes a contigious representation of the lyrics as vowel phonems was needed. \n",
    "\n",
    "The proccess used for sequence matching needed a string representation, therefore I mapped each of the phonems to a character, and created a reverse lookup table. This table can be used to find the word that a phonem in a particular position was originally a part of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakdown of words by vowel pronunciation\n",
      "[['IH0'], ['AA1'], ['AA1'], ['EH1', 'IY0'], ['IY1'], ['IY1'], ['AA1'], ['AA1'], ['EH1', 'IY0'], ['EH1'], ['AA1', 'AH0'], ['AA1'], ['IH0'], ['EH1', 'ER0'], ['AO0', 'EH1', 'IY0'], ['AA1'], ['AH0', 'EH1', 'IY0'], ['IY1'], ['ER1', 'AH0'], ['AH1'], ['AA1'], ['AH0'], ['ER1', 'AH0'], ['IY1'], ['UH1'], ['AA1'], ['AH0'], ['EH1', 'IY0'], ['AH0'], ['AA1'], ['AA1'], ['AH1'], ['IY1'], ['IY1'], ['AA1'], ['ER0', 'EH1', 'IH0'], ['AH1'], ['IY1'], ['OW1'], ['AW1'], ['AH0'], ['OW1'], ['AW1'], ['OW1'], ['OW1'], ['AW1'], ['IY1'], ['OW1', 'AH0'], ['IH0'], ['AW1'], ['AH1'], ['AH0'], ['ER1'], ['OW1'], ['AH1'], ['AW1'], ['IY1'], ['OW1', 'IH0'], ['AW1'], ['EH1', 'IY0', 'IY0'], ['OW1', 'IH0'], ['AW1'], ['AH0'], ['AA1'], ['AH1'], ['AW1'], ['AY1'], ['AH1'], ['OW1', 'ER0'], [], ['AE1'], ['AE1'], ['AH0'], ['AE1', 'AH0'], ['OW1'], ['EH1'], ['OW1'], ['AE1', 'AH0', 'IY0'], ['OW1'], ['EH1'], ['OW1'], ['AE1', 'AH0'], ['IY1'], ['OW1'], ['IY1'], ['OW1'], ['AE1'], ['AH1'], ['IY1'], ['OW1'], ['IH1'], ['AH1'], ['AE1'], ['IY1', 'IY0'], ['OW1'], ['IY1'], ['OW1'], ['AE1'], ['IH0'], ['IY1'], ['OW1'], ['IH0'], ['OW1'], ['AE1'], ['IH1', 'IY0'], ['OW1'], ['IH0'], ['OW1'], ['AE1', 'ER0'], ['IY1'], ['OW1'], ['IY1'], ['OW1'], ['AE1'], ['AH1'], ['IY1'], ['OW1'], ['IY1'], ['OW1'], ['AE1'], ['AE1'], ['IY1'], ['OW1'], ['EH1'], ['IY1'], ['OW1'], ['AE1'], ['AH0'], ['IH0'], ['OW1', 'AH0'], ['OW1'], ['AE1'], ['EH1'], ['IH0'], ['AE1'], ['AH0'], ['AH0'], ['AE1'], ['AH0', 'EH1'], ['OW1'], ['IH0'], ['OW1'], ['AE1', 'AH0', 'IY0'], ['IY1'], ['EH1', 'ER0'], ['OW1'], ['AE1', 'ER0'], ['IH0'], ['OW1', 'AH0'], ['AH0'], ['OW1'], ['IH0'], ['OW1'], ['AE1'], ['IH0'], ['UW1'], ['EH1', 'ER0'], ['UW1'], ['ER0', 'EH1'], ['IH0'], ['AH0'], ['UW1', 'IH0'], ['AH0'], ['OW1', 'AH0'], ['UW1'], ['OW1'], ['IH0'], ['UW1'], ['EH1', 'ER0'], ['EH1', 'ER0'], ['EH1'], ['IH0'], ['OW1'], ['UW1'], ['OW1', 'IY0'], ['EH1'], ['AH1'], ['AA1'], ['UW1'], ['AA1'], ['IH1'], ['AO1'], ['AE1'], ['AH0'], ['OW1'], ['IH0'], ['ER0', 'UW1', 'AH0', 'IY0'], ['AH1'], ['AH1'], ['IH0'], ['EY1', 'AO1', 'UW1', 'AH1', 'UW1', 'EY1'], ['AY1'], ['UW1'], ['EH1', 'ER0'], ['UW1'], ['EH1', 'ER0'], ['UW1'], ['ER0', 'EH1'], ['IH0'], ['AH0'], ['UW1', 'IH0'], ['AH0'], ['OW1', 'AH0'], ['UW1'], ['OW1'], ['IH0'], ['UW1'], ['EH1', 'ER0'], ['EH1', 'ER0'], ['EH1'], ['IH0'], ['OW1'], ['UW1'], ['OW1', 'IY0'], ['EH1'], ['AH1'], ['AA1'], ['UW1'], ['AA1'], ['IH1'], ['AO1'], ['AE1'], ['AH0'], ['OW1'], ['IH0'], ['ER0', 'UW1', 'AH0', 'IY0'], ['AH1'], ['AH1'], ['IH0'], ['EY1', 'AO1', 'UW1', 'AH1', 'UW1', 'EY1'], ['AY1'], ['UW1'], ['EH1', 'ER0']]\n",
      "Grouped phonems, with lookup table to find original word\n",
      "['IH0', 'AA1', 'AA1', 'EH1', 'IY0', 'IY1', 'IY1', 'AA1', 'AA1', 'EH1', 'IY0', 'EH1', 'AA1', 'AH0', 'AA1', 'IH0', 'EH1', 'ER0', 'AO0', 'EH1', 'IY0', 'AA1', 'AH0', 'EH1', 'IY0', 'IY1', 'ER1', 'AH0', 'AH1', 'AA1', 'AH0', 'ER1', 'AH0', 'IY1', 'UH1', 'AA1', 'AH0', 'EH1', 'IY0', 'AH0', 'AA1', 'AA1', 'AH1', 'IY1', 'IY1', 'AA1', 'ER0', 'EH1', 'IH0', 'AH1', 'IY1', 'OW1', 'AW1', 'AH0', 'OW1', 'AW1', 'OW1', 'OW1', 'AW1', 'IY1', 'OW1', 'AH0', 'IH0', 'AW1', 'AH1', 'AH0', 'ER1', 'OW1', 'AH1', 'AW1', 'IY1', 'OW1', 'IH0', 'AW1', 'EH1', 'IY0', 'IY0', 'OW1', 'IH0', 'AW1', 'AH0', 'AA1', 'AH1', 'AW1', 'AY1', 'AH1', 'OW1', 'ER0', 'AE1', 'AE1', 'AH0', 'AE1', 'AH0', 'OW1', 'EH1', 'OW1', 'AE1', 'AH0', 'IY0', 'OW1', 'EH1', 'OW1', 'AE1', 'AH0', 'IY1', 'OW1', 'IY1', 'OW1', 'AE1', 'AH1', 'IY1', 'OW1', 'IH1', 'AH1', 'AE1', 'IY1', 'IY0', 'OW1', 'IY1', 'OW1', 'AE1', 'IH0', 'IY1', 'OW1', 'IH0', 'OW1', 'AE1', 'IH1', 'IY0', 'OW1', 'IH0', 'OW1', 'AE1', 'ER0', 'IY1', 'OW1', 'IY1', 'OW1', 'AE1', 'AH1', 'IY1', 'OW1', 'IY1', 'OW1', 'AE1', 'AE1', 'IY1', 'OW1', 'EH1', 'IY1', 'OW1', 'AE1', 'AH0', 'IH0', 'OW1', 'AH0', 'OW1', 'AE1', 'EH1', 'IH0', 'AE1', 'AH0', 'AH0', 'AE1', 'AH0', 'EH1', 'OW1', 'IH0', 'OW1', 'AE1', 'AH0', 'IY0', 'IY1', 'EH1', 'ER0', 'OW1', 'AE1', 'ER0', 'IH0', 'OW1', 'AH0', 'AH0', 'OW1', 'IH0', 'OW1', 'AE1', 'IH0', 'UW1', 'EH1', 'ER0', 'UW1', 'ER0', 'EH1', 'IH0', 'AH0', 'UW1', 'IH0', 'AH0', 'OW1', 'AH0', 'UW1', 'OW1', 'IH0', 'UW1', 'EH1', 'ER0', 'EH1', 'ER0', 'EH1', 'IH0', 'OW1', 'UW1', 'OW1', 'IY0', 'EH1', 'AH1', 'AA1', 'UW1', 'AA1', 'IH1', 'AO1', 'AE1', 'AH0', 'OW1', 'IH0', 'ER0', 'UW1', 'AH0', 'IY0', 'AH1', 'AH1', 'IH0', 'EY1', 'AO1', 'UW1', 'AH1', 'UW1', 'EY1', 'AY1', 'UW1', 'EH1', 'ER0', 'UW1', 'EH1', 'ER0', 'UW1', 'ER0', 'EH1', 'IH0', 'AH0', 'UW1', 'IH0', 'AH0', 'OW1', 'AH0', 'UW1', 'OW1', 'IH0', 'UW1', 'EH1', 'ER0', 'EH1', 'ER0', 'EH1', 'IH0', 'OW1', 'UW1', 'OW1', 'IY0', 'EH1', 'AH1', 'AA1', 'UW1', 'AA1', 'IH1', 'AO1', 'AE1', 'AH0', 'OW1', 'IH0', 'ER0', 'UW1', 'AH0', 'IY0', 'AH1', 'AH1', 'IH0', 'EY1', 'AO1', 'UW1', 'AH1', 'UW1', 'EY1', 'AY1', 'UW1', 'EH1', 'ER0']\n",
      "Contigious representation of phonems in a string\n",
      "maaioppaaioiacamijeioaciopkcdackcpraciocaadppajimdpqgcqgqqgpqcmgdckqdgpqmgiooqmgcadghdqjbbcbcqiqbcoqiqbcpqpqbdpqndbpoqpqbmpqmqbnoqmqbjpqpqbdpqpqbbpqipqbcmqcqbimbccbciqmqbcopijqbjmqccqmqbmsijsjimcsmcqcsqmsijijimqsqoidasanfbcqmjscoddmlfsdslhsijsijsjimcsmcqcsqmsijijimqsqoidasanfbcqmjscoddmlfsdslhsij\n"
     ]
    }
   ],
   "source": [
    "# Get pronunciation of each word in song\n",
    "words_pron = []\n",
    "for word in words:\n",
    "    words_pron.append(prons[word])\n",
    "    \n",
    "# Make lookup table\n",
    "lookup = []\n",
    "phones = []\n",
    "for wd_idx, word in enumerate(words_pron):\n",
    "    for phone in word:\n",
    "        lookup.append(wd_idx)\n",
    "        phones.append(phone)\n",
    "        \n",
    "# Convert phones into character sequence for matching\n",
    "keys,ls = to_int_keys_best(phones)\n",
    "char_keys = ''.join(list(map(lambda x: chr(97+x),keys)))\n",
    "\n",
    "print(\"Breakdown of words by vowel pronunciation\")\n",
    "print(words_pron)\n",
    "print(\"Grouped phonems, with lookup table to find original word\")\n",
    "print(phones)\n",
    "print(\"Contigious representation of phonems in a string\")\n",
    "print(char_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Finding Super Maximal Repeats\n",
    "The goal of the previous step was to prepare input for the search of maximal pairs: https://en.wikipedia.org/wiki/Maximal_pair. These pairs match nicely with the representation of phonems that we have thus far for rhyme-finding, as any given multisyllable rhyme will have a similar sequence of phonems. Super maximal repeats also have the property that they cannot be a subset of any other maximal pair, meaning when applied to phonems the rappers most complex rhymes were highlighted. This of course, does not factor in 'imperfect' rhymes, however this could potentially be addressed with fuzzy phonetic breakdowns.\n",
    "\n",
    "The supermax function seen below was my hand written wrapper https://github.com/matthewmazzanti/cmsc320finaltut/tree/master/repeats around the c++ library seqan: https://www.seqan.de/ specifically a 'find supermaximal repeats' function. This is a bioinformatics library designed for heavy genomic analysis, where sequence matching such as super maximal repeats is common and useful. Rather than a naive approach falling well into combinatoric explosion, this library is able to find super maximal repeats in linear time using suffix arrays https://en.wikipedia.org/wiki/Suffix_array , which becomes important for long text inputs with many phonems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[7, 1], 4, 'aaio'],\n",
       " [[35, 21], 4, 'acio'],\n",
       " [[81, 41], 2, 'ad'],\n",
       " [[88, 144], 2, 'bb'],\n",
       " [[114, 145], 2, 'bp'],\n",
       " [[39, 80, 13], 2, 'ca'],\n",
       " [[162, 90], 3, 'cbc'],\n",
       " [[161, 180], 2, 'cc'],\n",
       " [[30, 65], 2, 'ck'],\n",
       " [[61, 152], 2, 'cm'],\n",
       " [[103, 32], 2, 'cp'],\n",
       " [[82, 68], 2, 'dg'],\n",
       " [[79, 52], 2, 'gc'],\n",
       " [[58, 69], 3, 'gpq'],\n",
       " [[23, 3], 3, 'iop'],\n",
       " [[26, 31], 2, 'kc'],\n",
       " [[178, 153], 3, 'mqc'],\n",
       " [[76, 128], 3, 'oqm'],\n",
       " [[5, 43], 3, 'ppa'],\n",
       " [[70, 122], 3, 'pqm'],\n",
       " [[104, 134], 8, 'pqpqbdpq'],\n",
       " [[168, 95], 4, 'qbco'],\n",
       " [[175, 131], 3, 'qbj'],\n",
       " [[119, 184], 3, 'qbm'],\n",
       " [[51, 57, 54], 2, 'qg'],\n",
       " [[93, 99], 5, 'qiqbc'],\n",
       " [[77, 71], 3, 'qmg'],\n",
       " [[166, 129, 182, 123], 4, 'qmqb'],\n",
       " [[242, 187], 55, 'sijsjimcsmcqcsqmsijijimqsqoidasanfbcqmjscoddmlfsdslhsij']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find supermaximal repeats\n",
    "repeats = rpts.supermax(char_keys,1)\n",
    "repeats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Reverse Word Lookup\n",
    "Using the lookup table created earlier, the original words that generated the phonem sequence can be found. Thus, for a given sequence match we can see the word representation of the match.\n",
    "\n",
    "Here we begin to see some complex rhyme schemes that are found from the sequence matching, in particular \"he choked hes so mad but he wont\" and \"hes dope he knows that but hes broke\" from the sample above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['arms', 'are', 'heavy'], ['palms', 'are', 'sweaty']]\n",
      "[['calm', 'and', 'ready'], [\"mom's\", 'spaghetti']]\n",
      "[['clocks', 'run'], ['bombs', 'but']]\n",
      "[['snap', 'back'], ['stacked', 'that']]\n",
      "[['that', 'easy'], ['that', 'he']]\n",
      "[['to', 'drop'], ['the', 'clocks'], ['vomit', 'on']]\n",
      "[['the', 'lab', 'again'], ['to', 'reality']]\n",
      "[['to', 'the'], ['moment', 'and']]\n",
      "[['the', 'surface'], ['the', 'words']]\n",
      "[['opens', 'his'], ['to', 'his']]\n",
      "[['rabbit', 'he'], ['surface', 'he']]\n",
      "[['run', 'out'], ['come', 'out']]\n",
      "[['now', 'the'], ['down', 'the']]\n",
      "[['loud', 'he', 'opens'], ['out', \"he's\", 'choking']]\n",
      "[['spaghetti', \"he's\"], ['sweaty', 'knees']]\n",
      "[['nervous'], ['surface']]\n",
      "[['this', 'moment'], ['his', 'mobile']]\n",
      "[[\"everybody's\", 'joking'], [\"city's\", 'ropes', 'it']]\n",
      "[['knees', 'weak', 'arms'], ['he', 'keeps', 'on']]\n",
      "[[\"he's\", 'choking'], ['he', 'knows', 'his']]\n",
      "[['he', 'choked', \"he's\", 'so', 'mad', 'but', 'he', \"won't\"], [\"he's\", 'dope', 'he', 'knows', 'that', 'but', \"he's\", 'broke']]\n",
      "[['whole', 'rhapsody'], ['goes', 'gravity']]\n",
      "[['go', 'capture'], [\"don't\", 'matter']]\n",
      "[[\"won't\", 'have', 'it'], [\"don't\", 'pass', 'him']]\n",
      "[['wrote', 'down'], ['so', 'loud'], ['whole', 'crowd']]\n",
      "[['oh', 'there', 'goes', 'gravity'], ['oh', 'there', 'goes', 'rabbit']]\n",
      "[['joking', 'now'], ['choking', 'how']]\n",
      "[['yo', 'this', 'whole', 'rhapsody'], ['ropes', 'it', \"don't\", 'matter'], ['hope', 'it', \"don't\", 'pass'], ['knows', 'his', 'whole', 'back']]\n",
      "[['you', 'better', 'lose', 'yourself', 'in', 'the', 'music', 'the', 'moment', 'you', 'own', 'it', 'you', 'better', 'never', 'let', 'it', 'go', 'you', 'only', 'get', 'one', 'shot', 'do', 'not', 'miss', 'your', 'chance', 'to', 'blow', 'this', 'opportunity', 'comes', 'once', 'in', 'a', 'lifetime', 'you', 'better'], ['you', 'better', 'lose', 'yourself', 'in', 'the', 'music', 'the', 'moment', 'you', 'own', 'it', 'you', 'better', 'never', 'let', 'it', 'go', 'you', 'only', 'get', 'one', 'shot', 'do', 'not', 'miss', 'your', 'chance', 'to', 'blow', 'this', 'opportunity', 'comes', 'once', 'in', 'a', 'lifetime', 'you', 'better']]\n"
     ]
    }
   ],
   "source": [
    "# From repeat locations find words that were rhymed\n",
    "rhymes = []\n",
    "for locs, length, seq in repeats:\n",
    "    rhyme = []\n",
    "    for loc in locs:\n",
    "        phrase = []\n",
    "        for i in range(0,length):\n",
    "            phrase.append(lookup[loc + i])\n",
    "        phrase = rem_dup(phrase)\n",
    "        rhyme.append(list(map(lambda x: words[x], phrase)))\n",
    "\n",
    "    rhymes.append((rhyme,locs,length,seq))\n",
    "    \n",
    "for rhyme,_,_,_ in rhymes:\n",
    "    print(rhyme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: remove trival matches\n",
    "One issue with maximal repeats is that they will match perfectly simmilar patterns, such as the repeated chorus of the song. These matches are trivial, in that they contain exactly the same words throughout, and thus for effective analysis they must be removed from the set.\n",
    "\n",
    "To do so, I found the set difference compared to the set of words. If both sets have the same words, then the difference between the words set would be zero. If each contained unique words, the difference would be 1. In my code, I assumed that >50% word similarity could estimate a trivial match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['arms', 'are', 'heavy'], ['palms', 'are', 'sweaty']]\n",
      "[['calm', 'and', 'ready'], [\"mom's\", 'spaghetti']]\n",
      "[['clocks', 'run'], ['bombs', 'but']]\n",
      "[['snap', 'back'], ['stacked', 'that']]\n",
      "[['that', 'easy'], ['that', 'he']]\n",
      "[['to', 'drop'], ['the', 'clocks'], ['vomit', 'on']]\n",
      "[['the', 'lab', 'again'], ['to', 'reality']]\n",
      "[['to', 'the'], ['moment', 'and']]\n",
      "[['the', 'surface'], ['the', 'words']]\n",
      "[['opens', 'his'], ['to', 'his']]\n",
      "[['rabbit', 'he'], ['surface', 'he']]\n",
      "[['run', 'out'], ['come', 'out']]\n",
      "[['now', 'the'], ['down', 'the']]\n",
      "[['loud', 'he', 'opens'], ['out', \"he's\", 'choking']]\n",
      "[['spaghetti', \"he's\"], ['sweaty', 'knees']]\n",
      "[['nervous'], ['surface']]\n",
      "[['this', 'moment'], ['his', 'mobile']]\n",
      "[[\"everybody's\", 'joking'], [\"city's\", 'ropes', 'it']]\n",
      "[['knees', 'weak', 'arms'], ['he', 'keeps', 'on']]\n",
      "[[\"he's\", 'choking'], ['he', 'knows', 'his']]\n",
      "[['he', 'choked', \"he's\", 'so', 'mad', 'but', 'he', \"won't\"], [\"he's\", 'dope', 'he', 'knows', 'that', 'but', \"he's\", 'broke']]\n",
      "[['whole', 'rhapsody'], ['goes', 'gravity']]\n",
      "[['go', 'capture'], [\"don't\", 'matter']]\n",
      "[[\"won't\", 'have', 'it'], [\"don't\", 'pass', 'him']]\n",
      "[['wrote', 'down'], ['so', 'loud'], ['whole', 'crowd']]\n",
      "[['joking', 'now'], ['choking', 'how']]\n",
      "[['yo', 'this', 'whole', 'rhapsody'], ['ropes', 'it', \"don't\", 'matter'], ['hope', 'it', \"don't\", 'pass'], ['knows', 'his', 'whole', 'back']]\n"
     ]
    }
   ],
   "source": [
    "def similarity(set1, set2):\n",
    "    return (len(set1 - set2) + len(set2 - set1))/(len(set1)+len(set2))\n",
    "\n",
    "# Find unique rhymes\n",
    "rhymes_diff = []\n",
    "for rhyme,locs,length,seq in rhymes:\n",
    "    sets = []\n",
    "    for group in rhyme:\n",
    "        sets.append(set(group))\n",
    "\n",
    "    mask = [1] * len(sets)\n",
    "    for idx in it.combinations(range(0,len(sets)),2):\n",
    "        if similarity(sets[idx[0]],sets[idx[1]]) < .5:\n",
    "            mask[idx[1]] = 0\n",
    "\n",
    "    rhyme_diff = list(it.compress(rhyme, mask))\n",
    "    if(len(rhyme_diff) > 1):\n",
    "        rhymes_diff.append((rhyme_diff,locs,length,seq))\n",
    "\n",
    "for rhyme,_,_,_ in rhymes_diff:\n",
    "    print(rhyme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Feature Extraction\n",
    "Step 7 is where the project struggled and failed, as I was unsure of which features from the text to map. I found some basic ones, such as word count, unique word count, mean rhyme length, and more. I was however unsure of the validity of these measure, and did not know how to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean': 2.888888888888889, 'num_rhymes': 27, 'word_count': 233, 'unique_word_count': 118}\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "max_len = 0\n",
    "for _,locs,length,_ in rhymes_diff:\n",
    "    total += length\n",
    "    if max_len < length:\n",
    "        max_len = length\n",
    "\n",
    "denom = len(rhymes_diff)\n",
    "if(denom > 0):\n",
    "    mean = total/len(rhymes_diff)\n",
    "else:\n",
    "    mean = -1\n",
    "\n",
    "print({'mean':mean,\n",
    "        'num_rhymes':denom,\n",
    "        'word_count':len(words),\n",
    "        'unique_word_count':len(word_bag.keys())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
